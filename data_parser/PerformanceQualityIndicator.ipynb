{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import sqrt, sin, cos, pi, diff\n",
    "import random as rand\n",
    "import statistics as stats\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import scipy\n",
    "import scipy.signal as signal\n",
    "import plotly.io as pio\n",
    "import pickle\n",
    "from prettytable import PrettyTable\n",
    "import csv\n",
    "import os\n",
    "import yaml\n",
    "import re\n",
    "pio.renderers.default = \"notebook\"\n",
    "#pio.renderers.default = \"svg\"\n",
    "pickle_folder = \"pickle/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIRS = [\"output/pqi/data\", \"output/pqi/img/\", \"output/pqi/html/\", pickle_folder]\n",
    "for output_dir in OUTPUT_DIRS:\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLE FUNCTIONS\n",
    "def const_f(OFF):\n",
    "    return lambda x: OFF\n",
    "\n",
    "def sin_f(T, A=1, OFF=0, ABS=False):\n",
    "    if ABS:\n",
    "        return lambda x: abs(A*sin(x*T)+OFF)\n",
    "    else:\n",
    "        return lambda x: A*sin(x*T)+OFF\n",
    "\n",
    "def pulse_f(T, D, A=1, OFF=0):\n",
    "    return lambda x: A+OFF if (np.arange(NUM_SAMPLES) % T < D)[x] else OFF\n",
    "    \n",
    "# same as np.gradient(f)\n",
    "def gradient(f, start, stop, step):\n",
    "    deltas = []\n",
    "    f_prev = 0\n",
    "    for i in np.arange(start, stop, step):\n",
    "        deltas.append(f(i)-f_prev)\n",
    "        f_prev = f(i)\n",
    "    return deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "NUM_SAMPLES = 100\n",
    "measures = np.arange(0, NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Perfomance Quality\n",
    "The indicator summarizes:\n",
    "- the violation of a threshold\n",
    "- the amplitude of the variability (width and size)\n",
    "- the speed of the variability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ideal cloud would have zero variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "funcs = []\n",
    "funcs.append(const_f(10))\n",
    "\n",
    "fig = go.Figure()\n",
    "for i, func in enumerate(funcs):\n",
    "    fig.add_trace(go.Scatter(x=measures, y=[func(v) for v in measures], name=\"f\" + str(i)))\n",
    "    fig.add_trace(go.Scatter(x=measures, y=[stats.mean([func(v) for v in measures])]*NUM_SAMPLES, name=\"avg f\" + str(i)))\n",
    "fig.update_layout(\n",
    "        title=\"ideal cloud performance\",\n",
    "        title_x=0.5,\n",
    "        xaxis_title=\"time\",\n",
    "        yaxis_title=\"score\"\n",
    "    )\n",
    "fig.show()\n",
    "\n",
    "for i, func in enumerate(funcs):\n",
    "    print(\"f%d  -> avg: %.2f, std: %.2f\" % (i,\n",
    "                                            stats.mean([func(v) for v in measures]),\n",
    "                                            stats.stdev([func(v) for v in measures])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variation Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = []\n",
    "funcs.append(sin_f(1/NUM_SAMPLES * 2*np.pi, A=5))\n",
    "funcs.append(sin_f(1/NUM_SAMPLES * 4*np.pi, A=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLDS = [0.1, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i, func in enumerate(funcs):\n",
    "    fig.add_trace(go.Scatter(x=measures, y=[func(v) for v in measures], name=\"f\" + str(i)))\n",
    "    threshold = THRESHOLDS[i]\n",
    "    fy = [func(v) for v in measures]\n",
    "    mean_y = stats.mean(fy)\n",
    "    max_y = max(fy)\n",
    "    fig.add_shape(\n",
    "            # filled Rectangle\n",
    "                type=\"rect\",\n",
    "                x0=0,\n",
    "                y0=mean_y+threshold*max_y,\n",
    "                x1=NUM_SAMPLES,\n",
    "                y1=mean_y-threshold*max_y,\n",
    "                fillcolor=px.colors.qualitative.Plotly[i],\n",
    "                opacity=0.5,\n",
    "                layer=\"below\",\n",
    "            )    \n",
    "fig.update_layout(\n",
    "    title=\"variation entity\",\n",
    "    title_x=0.5,\n",
    "    xaxis_title=\"time\",\n",
    "    yaxis_title=\"score\"\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "for i, func in enumerate(funcs):\n",
    "    fy = [func(v) for v in measures]\n",
    "    mean_y = stats.mean(fy)\n",
    "    max_y = max(fy)\n",
    "    threshold = THRESHOLDS[i]\n",
    "    I_all = np.trapz(fy, x=measures)\n",
    "    I_neg = np.trapz(list(map(lambda x: x if x < mean_y-threshold*max_y else 0, fy)), x=measures)\n",
    "    print(\"f%d  -> avg: %.2f, std: %.2f, int: %.2f, int_neg: %.2f\" % (\n",
    "        i,\n",
    "        stats.mean([func(v) for v in measures]),\n",
    "        stats.stdev([func(v) for v in measures]),\n",
    "        I_all,\n",
    "        I_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The integral measures the entity of the variation: integral ~ variation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variability\n",
    "Same degradation entity (integral = duration*amplitude) but different variability: short and deep degradation pulses VS long and shallow degradations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = []\n",
    "funcs.append(pulse_f(50, D=25, A=1))\n",
    "funcs.append(pulse_f(20, D=5, A=2))\n",
    "funcs.append(pulse_f(10, D=1, A=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i, func in enumerate(funcs):\n",
    "    fig.add_trace(go.Scatter(x=measures, y=[func(v) for v in measures], name=\"f\" + str(i)))\n",
    "fig.update_layout(\n",
    "    title=\"slow vs fast pulses\",\n",
    "    title_x=0.5,\n",
    "    xaxis_title=\"time\",\n",
    "    yaxis_title=\"score\"\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "for i, func in enumerate(funcs):\n",
    "    I = np.trapz([func(v) for v in measures], x=measures)\n",
    "    print(\"f%d  -> avg: %.2f, std: %.2f, int: %.2f\" % (\n",
    "        i,\n",
    "        stats.mean([func(v) for v in measures]),\n",
    "        stats.stdev([func(v) for v in measures]),\n",
    "        I))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STD measures the variability: std ~ variability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variation Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same degradation amplitude but different speeds: slower variation VS faster variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = []\n",
    "funcs.append(sin_f(1/NUM_SAMPLES * 2*np.pi))\n",
    "funcs.append(sin_f(2/NUM_SAMPLES * 2*np.pi))\n",
    "funcs.append(sin_f(4/NUM_SAMPLES * 2*np.pi))\n",
    "funcs.append(sin_f(4/NUM_SAMPLES * 2*np.pi, A=2))\n",
    "funcs.append(sin_f(8/NUM_SAMPLES * 2*np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i, func in enumerate(funcs):\n",
    "    fig.add_trace(go.Scatter(x=measures, y=[func(v) for v in measures], name=\"f\" + str(i)))\n",
    "fig.update_layout(\n",
    "        title=\"variation speed\",\n",
    "        title_x=0.5,\n",
    "        xaxis_title=\"time\",\n",
    "        yaxis_title=\"score\"\n",
    "    )\n",
    "fig.show()\n",
    "\n",
    "for i, func in enumerate(funcs):\n",
    "    print(\"f%d  -> avg: %.2f, std: %.2f, int: %.2f, int_e: %.2f\" % (\n",
    "        i,\n",
    "        stats.mean([func(v) for v in measures]),\n",
    "        stats.stdev([func(v) for v in measures]),\n",
    "        scipy.integrate.quad(func, 0, NUM_SAMPLES)[0],\n",
    "        scipy.integrate.quad(func, 0, NUM_SAMPLES)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i, func in enumerate(funcs):\n",
    "    fig.add_trace(go.Scatter(x=measures, y=gradient(func,0, NUM_SAMPLES, 1), name=\"f\" + str(i)))\n",
    "fig.update_layout(\n",
    "        title=\"gradient variation\",\n",
    "        title_x=0.5,\n",
    "        xaxis_title=\"time\",\n",
    "        yaxis_title=\"score\"\n",
    "    )\n",
    "fig.show()\n",
    "\n",
    "for i, func in enumerate(funcs):\n",
    "    print(\"f%d  -> int: %.2f, avg-grad: %.2f, std-grad: %.2f, diff-avg: %.2f, diff-std: %.2f\" % (\n",
    "        i,\n",
    "        np.trapz(gradient(func,0, NUM_SAMPLES, 1)),\n",
    "        stats.mean(gradient(func,0, NUM_SAMPLES, 1)),\n",
    "        stats.stdev(gradient(func,0, NUM_SAMPLES, 1)),\n",
    "        stats.mean(diff([func(v) for v in measures])/diff(measures)),\n",
    "        stats.stdev(diff([func(v) for v in measures])/diff(measures))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STD of gradient measure the speed: STD of gradient ~ speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Quality\n",
    "The required quality depends on the application:\n",
    "- some application requires slow variations while other can tolerate faster variations\n",
    "- some application requires small variations while other can tolerate bigger variations\n",
    "- a slower variation allows a more accurate prediction\n",
    "- only negative variations (slowdowns) can be considered (positive variations are speedups and will not negatively affect the application performance)\n",
    "\n",
    "\n",
    "## Indicator\n",
    "The quality indicator could be a float obtained from a formula with the following parameters:\n",
    "- threshold\n",
    "- weight for variation entity\n",
    "- weight for variation behavior\n",
    "- weight for variation speed\n",
    "\n",
    "The parameters are tuned based on the application, e.g.:\n",
    "- cloud application: quality_indicator(data_sample, th=20%, ve=0.5, vb=0.25, vs=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the average\n",
    "def avg_arr(data):\n",
    "    return np.full_like(data, np.average(data), dtype=float)\n",
    "\n",
    "# compute the difference from the average\n",
    "def diff_arr(data, absolute=False):\n",
    "    if absolute:\n",
    "        return np.absolute(data - avg_arr(data))\n",
    "    else:\n",
    "        return data - avg_arr(data)\n",
    "\n",
    "# compute the division to calculate the absolute variation\n",
    "def div_arr(data, absolute=False):\n",
    "    if absolute:\n",
    "        return np.absolute(np.divide(data, avg_arr(data)) - np.ones(np.size(data)))\n",
    "    else:\n",
    "        return np.divide(data, avg_arr(data)) - np.ones(np.size(data))\n",
    "\n",
    "# compute the gradient\n",
    "def gradient_arr(data):\n",
    "    return np.gradient(data)\n",
    "\n",
    "def violations(data, threshold):\n",
    "    return len(list(filter(lambda v: abs(v)>threshold, data)))/len(data)\n",
    "\n",
    "# compute the quality indicator as a weighted sum\n",
    "def qi_s(integ, std, grad_std, w_integ, w_std, w_grad_std):\n",
    "    return (w_integ*abs(integ) + w_std*abs(std) + w_grad_std*abs(grad_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.05, 0.1, 0.2]\n",
    "\n",
    "def init_table(table):\n",
    "    table.add_column(\"\", [\"avg\", \"score/$\", \"std (%)\",\n",
    "                      \"viol. (th=\"+str(thresholds[0])+\") (%)\",\n",
    "                      # \"integral\", \"integral + -\", \"integral -\",\n",
    "                      \"integral (%)\", \"integral + - (%)\", \"integral - (%)\", \"integral th - (%)\",\n",
    "                      \"gradient-mean\", \"gradient-std (%)\",\n",
    "                      \"div-min (%)\", \"div-max (%)\",\n",
    "                      \"qi_1 (general)\", \"qi_2 (deg.)\", \"qi_3 (var.)\", \"qi_4 (speed)\"])\n",
    "    \n",
    "def check_htr(x, test, threshold=0):\n",
    "    # check if the test is HIB or LIB\n",
    "    if test[\"htr\"] == \"HIB\":\n",
    "        # HIB: take only negative values\n",
    "        return x < threshold\n",
    "    elif test[\"htr\"] == \"LIB\":\n",
    "        # LIB: take only positive values\n",
    "        return x > threshold\n",
    "    \n",
    "def instance_cost(cfg, instance):\n",
    "    # read the instance cost from the config\n",
    "    for vm in cfg[\"vms\"]:\n",
    "        if cfg[\"vms\"][vm][\"name\"] == instance:\n",
    "            return cfg[\"vms\"][vm][\"price\"]\n",
    "\n",
    "def get_valid_filename(s):\n",
    "    s = str(s).strip().replace(' ', '_')\n",
    "    return re.sub(r'(?u)[^-\\w.]', '', s)\n",
    "        \n",
    "def get_filename(provider, bench_name, extracted_name, key):\n",
    "    return provider + \"_\" + get_valid_filename(bench_name + \"_\" + extracted_name) + \"_\" + str(key)[0:5]\n",
    "        \n",
    "def get_trace_name(name):\n",
    "    if provider == \"aws\":\n",
    "        #return name.replace(\"-central\", \"\")\n",
    "        return name[:name.find(\" -\")]+\"-\"+name[-1:]\n",
    "    elif provider == \"azure\":\n",
    "        return name\n",
    "    elif provider == \"gcp\":\n",
    "        return name\n",
    "    elif provider == \"egi\":\n",
    "        return name\n",
    "\n",
    "def calculate(table, fig, provider, instance, instance_cost, test_key, test, times, values, output_writer=None):\n",
    "    # avg\n",
    "    avg = stats.mean(values)\n",
    "    # min, max\n",
    "    min_v = min(values)\n",
    "    max_v = max(values)\n",
    "    # std, std%\n",
    "    std = stats.stdev(values)\n",
    "    std_perc = std/avg\n",
    "    # score/$\n",
    "    score_dollar = avg/instance_cost if test[\"htr\"] == \"HIB\" else (1/avg)/instance_cost\n",
    "    # difference array (values-avg)\n",
    "    diff_a = diff_arr(values)\n",
    "    diff_a_abs = diff_arr(values, absolute=True)\n",
    "    # division array (values/avg - 1)\n",
    "    div_a = div_arr(values)\n",
    "    div_a_abs = div_arr(values, absolute=True)\n",
    "    # violations\n",
    "    viol = violations(div_a, thresholds[0])\n",
    "    # gradient array\n",
    "    grad_a = gradient_arr(values)\n",
    "    grad_avg = stats.mean(grad_a)\n",
    "    grad_std_perc = stats.stdev(grad_a)/avg\n",
    "    # integral\n",
    "    # all: sum of positive and negative variations\n",
    "    # abs: sum of abs(variations)\n",
    "    # neg: sum of negative variations (if HIB) or positive variations (if LIB)\n",
    "    integral_all = np.trapz(diff_a, x=np.arange(len(times)))\n",
    "    integral_abs = np.trapz(diff_a_abs, x=np.arange(len(times)))\n",
    "    integral_neg = np.trapz(list(map(lambda x: x if check_htr(x, test) else 0, diff_arr(values))), x=np.arange(len(times)))\n",
    "\n",
    "    # div_all: sum of variations (percentage)\n",
    "    # div_abs: sum of abs(variations) (percentage)\n",
    "    # div_neg_th: sum of negative variations (if HIB) or positive variations (if LIB) with threshold (percentage)\n",
    "    integral_div_all = np.trapz(div_a, x=np.arange(len(times)))/len(times)\n",
    "    integral_div_abs = np.trapz(div_a_abs, x=np.arange(len(times)))/len(times)\n",
    "    integral_div_neg = np.trapz(list(map(lambda x: x if check_htr(x, test) else 0, div_a)), x=np.arange(len(times)))/len(times)\n",
    "    integral_div_neg_th = []\n",
    "    for threshold in thresholds:\n",
    "        integral_div_neg_th.append(np.trapz(list(map(lambda x: x if check_htr(x, test, threshold) else 0, div_a)), x=np.arange(len(times)))/len(times))\n",
    "\n",
    "    # quality indicators\n",
    "    qi_1 = qi_s(integral_div_neg, std_perc, grad_std_perc, 1/3, 1/3, 1/3)\n",
    "    qi_2 = qi_s(integral_div_neg, std_perc, grad_std_perc, 0.80, 0.10, 0.10)\n",
    "    qi_3 = qi_s(integral_div_neg, std_perc, grad_std_perc, 0.10, 0.80, 0.10)\n",
    "    qi_4 = qi_s(integral_div_neg, std_perc, grad_std_perc, 0.10, 0.10, 0.80)\n",
    "\n",
    "    table.add_column(get_trace_name(instance),\n",
    "                     [avg,\n",
    "                      score_dollar,\n",
    "                      std_perc*100,\n",
    "                      viol*100,\n",
    "                      # integral_all*100, integral_abs*100, integral_neg*100,\n",
    "                      integral_div_all*100, integral_div_abs*100, integral_div_neg*100, integral_div_neg_th[1]*100,\n",
    "                      grad_avg, grad_std_perc*100,\n",
    "                      min(div_a)*100, max(div_a)*100,\n",
    "                      qi_1*100, qi_2*100, qi_3*100, qi_4*100])\n",
    "    \n",
    "    #fig.add_trace(go.Scatter(x=times, y=values, mode='lines', name=instance))\n",
    "    #fig.add_trace(go.Scatter(x=times, y=avg_arr(values), mode='lines', name=instance + \" avg\"))\n",
    "    #fig.add_trace(go.Scatter(x=times, y=diff_a, mode='lines', name=instance + \" diff\"))\n",
    "    #fig.add_trace(go.Scatter(x=times, y=div_a, mode='lines', name=instance + \" div\"))\n",
    "    #fig.add_trace(go.Scatter(x=times, y=grad_a, mode='lines', name=instance + \" gradient\"))\n",
    "    fig.add_trace(go.Bar(\n",
    "            name=get_trace_name(instance) + \" PQI\",\n",
    "            x=[get_trace_name(instance)], y=[qi_1]))\n",
    "    \n",
    "    if output_writer:\n",
    "        output_writer.writerow([provider,\n",
    "                                instance,\n",
    "                                test_key,\n",
    "                                test[\"bench_name\"],\n",
    "                                test[\"extracted_name\"],\n",
    "                                test[\"extracted_unit\"],\n",
    "                                avg,\n",
    "                                min_v,\n",
    "                                max_v,\n",
    "                                std,\n",
    "                                score_dollar,\n",
    "                                std_perc,\n",
    "                                integral_div_neg,\n",
    "                                integral_div_neg_th[0],\n",
    "                                integral_div_neg_th[1],\n",
    "                                integral_div_neg_th[2],\n",
    "                                grad_std_perc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = []\n",
    "funcs.append(sin_f(1/NUM_SAMPLES * 2*np.pi, OFF=10))\n",
    "#funcs.append(sin_f(2/NUM_SAMPLES * 2*np.pi, OFF=10))\n",
    "funcs.append(sin_f(4/NUM_SAMPLES * 2*np.pi, OFF=10))\n",
    "funcs.append(pulse_f(50, D=25, A=2, OFF=9))\n",
    "funcs.append(pulse_f(10, D=1, A=-3, OFF=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "table = PrettyTable()\n",
    "init_table(table)\n",
    "\n",
    "for i, func in enumerate(funcs):\n",
    "    times = np.arange(NUM_SAMPLES)\n",
    "    values = [func(v) for v in times]\n",
    "    calculate(table, fig, \"\", \"f\"+str(i), 1, \"t1\", {\"htr\": \"HIB\"}, times, values)\n",
    "\n",
    "table.float_format = \".2\"\n",
    "print(table)\n",
    "fig.update_layout(autosize=True)\n",
    "fig.update_yaxes(automargin=True)\n",
    "fig.update_layout(\n",
    "    title_x=0.5,\n",
    "    xaxis_title=\"time\",\n",
    "    yaxis_title=\"result\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load prepared data\n",
    "tests_uni = pickle.load(open(pickle_folder + \"tests_uni.p\", \"rb\"))\n",
    "\n",
    "for provider in [\"aws\", \"azure\", \"gcp\"]: #[\"egi\"]: \n",
    "    data = pickle.load(open(pickle_folder + provider + \".p\", \"rb\"))\n",
    "    config_file = \"config_data_parser_\" + provider + \".yml\"\n",
    "    with open(config_file, 'r') as ymlfile:\n",
    "        cfg = yaml.load(ymlfile, Loader=yaml.FullLoader)\n",
    "        \n",
    "    with open(\"output/pqi/data/\" + provider + \"_pqi.csv\", mode='w') as output_file:\n",
    "        output_writer = csv.writer(output_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        output_writer.writerow([\"provider\",\"instance\",\"bench_key\",\"bench_name\",\"extracted_name\",\"unit\",\"avg\",\"min\",\"max\",\"std\",\"score_$\",\"std_perc\",\"integral_neg\",\"integral_neg_th_5\",\"integral_neg_th_10\",\"integral_neg_th_20\",\"grad_std_perc\"])\n",
    "\n",
    "        for key, grp in data:\n",
    "            print(tests_uni[key])\n",
    "            print(\"\\n\")\n",
    "            fig = go.Figure()\n",
    "            gbid = grp.groupby(\"id\")\n",
    "\n",
    "            table = PrettyTable()\n",
    "            init_table(table)\n",
    "\n",
    "            for key2, grp2 in gbid:        \n",
    "                times = grp2[\"time\"]\n",
    "                values = grp2[\"value\"]\n",
    "\n",
    "                calculate(table, fig, provider, key2, instance_cost(cfg, key2), key, tests_uni[key], times, values, output_writer)\n",
    "\n",
    "            table.float_format = \".2\"\n",
    "            print(table)\n",
    "            fig.update_layout(autosize=True)\n",
    "            fig.update_yaxes(automargin=True)\n",
    "            fig.update_layout(\n",
    "                title=provider + \" / \" + tests_uni[key][\"bench_name\"] + \" - \" + tests_uni[key][\"extracted_name\"] + \" (\" + tests_uni[key][\"extracted_unit\"] + \")\",\n",
    "                title_x=0.5,\n",
    "                xaxis_title=\"instance\",\n",
    "                yaxis_title=\"PQI\",\n",
    "                showlegend=False\n",
    "            )\n",
    "            fig.write_html(\"output/pqi/html/\" + get_filename(provider, tests_uni[key][\"bench_name\"], tests_uni[key][\"extracted_name\"], key) + \".html\", include_plotlyjs=\"cdn\")\n",
    "            fig.write_image(\"output/pqi/img/\" + get_filename(provider, tests_uni[key][\"bench_name\"], tests_uni[key][\"extracted_name\"], key) + \".png\", scale=2)\n",
    "            fig.show()\n",
    "            print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
